---
layout: default
title: Publications
permalink: /publications/
---

<h4>LIMMITS’24: Multi-speaker, Multi-lingual Indic TTS with voice cloning</h4> 

Abhayjeet Singh, Amala Nagireddi, G Deekshitha, Jesuraja Bandekar, R Roopa, Sandhya Badiger, <u>Sathvik Udupa</u>, Prasanta Kumar Ghosh, Hema A Murthy, Pranaw Kumar, Keiichi Tokuda, Mark Hasegawa-Johnson, Philipp Olbrich

<i>IEEE ICASSP Workshops, 2024</i> [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Bi1QvpIAAAAJ&sortby=pubdate&citation_for_view=Bi1QvpIAAAAJ:_FxGoFyzp5QC">link</a>] [<span style="color:green">speech synthesis</span>]

---

<h4>A machine‐learning tool to identify bistable states from calcium imaging data</h4>

Aalok Varma, <u>Sathvik Udupa</u>, Mohini Sengupta, Prasanta Kumar Ghosh, Vatsala Thirumalai

<i>The Journal of Physiology, 2024</i> [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Bi1QvpIAAAAJ&sortby=pubdate&citation_for_view=Bi1QvpIAAAAJ:9yKSN-GCB0IC">link</a>] [<span style="color:grey">machine learning</span>]

---

<h4>Lightweight, Multi-speaker, Multi-lingual Indic Text-To-Speech</h4>

Abhayjeet Singh, Amala Nagireddi, Anjali Jayakumar, G Deekshitha, Jesuraja Bandekar, R Roopa, Sandhya Badiger, <u>Sathvik Udupa</u>, Saurabh Kumar, Prasanta Kumar Ghosh, Hema A Murthy, Heiga Zen, Pranaw Kumar, Kamal Kant, Amol Bole, Bira Chandra Singh, Keiichi Tokuda, Mark Hasegawa-Johnson, Philipp Olbrich

<i>IEEE Open Journal of Signal Processing, 2024</i> [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Bi1QvpIAAAAJ&sortby=pubdate&citation_for_view=Bi1QvpIAAAAJ:ufrVoPGSRksC">link</a>] [<span style="color:green">speech synthesis</span>]

---

<h4>Adapter pre-training for improved speech recognition in unseen domains using low resource adapter tuning of self-supervised models</h4>

<u>Sathvik Udupa</u>, Jesuraj Bandekar, Saurabh Kumar, Savitha Murthy, Priyanka Pai, Srinivasa Raghavan, Raoul Nanavati, Prasanta Kumar Ghosh

<i>INTERSPEECH 2024</i> [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Bi1QvpIAAAAJ&sortby=pubdate&citation_for_view=Bi1QvpIAAAAJ:Se3iqnhoufwC">link</a>] [<span style="color:red">speech recognition</span>]

---

<h4>IndicMOS: Multilingual MOS Prediction for 7 Indian languages</h4>
<u>Sathvik Udupa</u>, Soumi Maiti, Prasanta Kumar Ghosh

<i>INTERSPEECH 2024</i> [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Bi1QvpIAAAAJ&sortby=pubdate&citation_for_view=Bi1QvpIAAAAJ:LkGwnXOMwfcC">link</a>] [<span style="color:brown">speech quality estimation</span>]

---
<h4>Articulatory synthesis using representations learnt through phonetic label-aware contrastive loss</h4>
Jesuraj Bandekar, <u>Sathvik Udupa</u>, Prasanta Kumar Ghosh

<i>INTERSPEECH 2024</i> [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Bi1QvpIAAAAJ&sortby=pubdate&citation_for_view=Bi1QvpIAAAAJ:roLk4NBRz8UC">link</a>] [<span style="color:orange">speech production</span>]

---

<h4>Gated Multi Encoders and Multitask Objectives for Dialectal Speech Recognition in Indian Languages</h4>

<u>Sathvik Udupa</u>, Jesuraja Bandekar, G Deekshitha, Saurabh Kumar, Prasanta Kumar Ghosh, Sandhya Badiger, Abhayjeet Singh, Savitha Murthy, Priyanka Pai, Srinivasa Raghavan, Raoul Nanavati

<i>IEEE ASRU 2023</i> [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Bi1QvpIAAAAJ&sortby=pubdate&citation_for_view=Bi1QvpIAAAAJ:WF5omc3nYNoC">link</a>] [<span style="color:red">speech recognition</span>]

---

<h4>Improved acoustic-to-articulatory inversion using representations from pretrained self-supervised learning models</h4>

<u>Sathvik Udupa</u>, C Siddarth, Prasanta Kumar Ghosh

<i>IEEE ICASSP 2023</i> [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Bi1QvpIAAAAJ&sortby=pubdate&citation_for_view=Bi1QvpIAAAAJ:zYLM7Y9cAGgC">link</a>] [<span style="color:orange">speech production</span>]

---

<h4>Real-Time MRI Video synthesis from time aligned phonemes with sequence-to-sequence networks</h4>

<u>Sathvik Udupa</u>, Prasanta Kumar Ghosh

<i>IEEE ICASSP 2023</i> [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Bi1QvpIAAAAJ&sortby=pubdate&citation_for_view=Bi1QvpIAAAAJ:UeHWp8X0CEIC">link</a>] [<span style="color:orange">speech production</span>]

---

<h4>Exploring a classification approach using quantised articulatory movements for acoustic to articulatory inversion</h4>

Jesuraj Bandekar, <u>Sathvik Udupa</u>, Prasanta Kumar Ghosh

<i>INTERSPEECH 2023</i> [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Bi1QvpIAAAAJ&sortby=pubdate&citation_for_view=Bi1QvpIAAAAJ:Y0pCki6q_DkC">link</a>] [<span style="color:orange">speech production</span>]


---

<h4>Streaming model for Acoustic to Articulatory Inversion with transformer networks</h4>

<u>Sathvik Udupa</u>, Aravind Illa, Prasanta Kumar Ghosh

<i>INTERSPEECH 2022</i> [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Bi1QvpIAAAAJ&sortby=pubdate&citation_for_view=Bi1QvpIAAAAJ:qjMakFHDy7sC">link</a>] [<span style="color:orange">speech production</span>]

---

<h4>Estimating articulatory movements in speech production with transformer networks</h4>

<u>Sathvik Udupa</u>, Anwesha Roy, Abhayjeet Singh, Aravind Illa, Prasanta Kumar Ghosh

<i>INTERSPEECH 2021</i> [<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Bi1QvpIAAAAJ&sortby=pubdate&citation_for_view=Bi1QvpIAAAAJ:u5HHmVD_uO8C">link</a>] [<span style="color:orange">speech production</span>]

---

